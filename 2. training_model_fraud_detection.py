# -*- coding: utf-8 -*-
"""training model fraud detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FQiLCeWHvaAQlyKX_dVYJkdnMAD4MMkL
"""

# Commented out IPython magic to ensure Python compatibility.
#instalasi TPOT
# %pip install tpot

# Commented out IPython magic to ensure Python compatibility.
# %pip install joblib

"""# Import Library"""

from tpot import TPOTClassifier
import tpot
from sklearn.model_selection import train_test_split, GridSearchCV
import pandas as pd
import  numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn import metrics
from sklearn.preprocessing import StandardScaler, MinMaxScaler

"""# Membaca data dummy untuk traning"""

# load data
data = pd.read_excel("result_dummy.xlsx")
data = data.drop(['Unnamed: 0', 'anum', 'bnum'], axis=1)
X = data.drop('is_fraud', axis=1).values
y = data['is_fraud'].values

# plot the class distribution
pd.value_counts(data['is_fraud'])

X

# split data into train, validation, and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

"""# Memulai membuat model dengan train data"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score
import joblib
from sklearn.tree import DecisionTreeClassifier
from joblib import dump, load

# model = tpot.TPOTClassifier(generations=5, population_size=20, random_state=42, verbosity=2)
model = RandomForestClassifier(bootstrap=False, criterion='entropy', max_features=0.6500000000000001, min_samples_leaf=19, min_samples_split=3, n_estimators=100)
model.fit(X_train, y_train)

#Save the model to a file
model_filename = 'rf_model.joblib'
dump(model, model_filename)

# To load the model later
loaded_model = load(model_filename)

y_pred = model.predict(X_test)
pred = model.predict(X_train)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

# Visualize Confusion Matrix
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score
print(f'Accuracy : {accuracy_score(y_test, y_pred)*100:.2f}%')
print(f'Precision : {precision_score(y_test, y_pred)*100:.2f}%')
print(f'Recall : {recall_score(y_test, y_pred)*100:.2f}%')

print("Confusion Matrix")
print(confusion_matrix(y_test, y_pred))
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
print('TN: ', tn)
print('FP: ', fp)
print('FN: ', fn)
print('TP: ', tp)
print("Classification report")
print(classification_report(y_test, y_pred))

accuracy = accuracy_score(y_test,y_pred)*100
precision = precision_score(y_test,y_pred, average='macro')*100
recall = recall_score(y_test,y_pred, average='macro')*100
f1 = f1_score(y_test,y_pred, average='macro')*100

print("\nMetrics:")
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

from sklearn import tree

# Visualisasi masing-masing pohon dalam Random Forest
fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 2), dpi=800)
for i in range(5):
    tree.plot_tree(model.estimators_[i], feature_names=data.columns[0:5],class_names = [str(class_name) for class_name in data['is_fraud'].unique()], filled=True, ax=axes[i])
    axes[i].set_title('Pohon {}'.format(i+1))

plt.show()